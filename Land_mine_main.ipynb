{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land mine classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Taha Parsayan\n",
    "Date: 2025 Jan 07\n",
    "\n",
    "Make a vertual environment\n",
    "\n",
    "python -m venv packages\n",
    "\n",
    "Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass\n",
    "\n",
    ".\\packages\\Scripts\\Activate.ps1\n",
    "\n",
    "python.exe -m pip install --upgrade pip\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import glob\n",
    "import Land_mine_data_management_functions as dmf\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from going_modular import data_setup, engine, model_builder, predictions\n",
    "import random\n",
    "from pathlib import Path\n",
    "from torchinfo import summary\n",
    "import torch.multiprocessing as mp\n",
    "from helper_functions import plot_loss_curves\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from going_modular.data_setup import create_dataloaders\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "print('Using device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "folder_path = 'DatainBrief_dataset_1'\n",
    "folder_path = os.path.join(current_path, folder_path)\n",
    "\n",
    "def walk_through_directory(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        print(f\"Root folder: {root}\")\n",
    "        print(f\"Subdirectories: {dirs}\")\n",
    "        print(f\"Files: {files}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "data_path = os.path.join(current_path, 'data')\n",
    "walk_through_directory(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data\n",
    "\n",
    "There are 5 folders containing images of landmines. \n",
    "We take 4 of them for training and 1 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import Land_mine_data_management_functions as dmf\n",
    "\n",
    "# 5-Class Landmine Types\n",
    "landmine_types = [\n",
    "    \"Free zone\",\n",
    "    \"Mine 0cm depth\",\n",
    "    \"Mine 1cm depth\",\n",
    "    \"Mine 5cm depth\",\n",
    "    \"Mine 10cm depth\"\n",
    "]\n",
    "\n",
    "train_date_folders = [\"03_03_2020\",\n",
    "                      \"13_02_2020\", \n",
    "                      \"17_02_2020\",\n",
    "                      \"20_02_2020\"]\n",
    "\n",
    "test_date_folders = [\"24_02_2020\"]\n",
    "\n",
    "# 5-Class Folders\n",
    "train_data_path_phase_3 = os.path.join(current_path, 'data', 'land_mine_phase_3', 'train')\n",
    "test_data_path_phase_3 = os.path.join(current_path, 'data', 'land_mine_phase_3', 'test')\n",
    "dmf.create_landmine_folders_phase_3(train_data_path_phase_3, landmine_types)\n",
    "dmf.copy_images_to_landmine_folders_phase_3(folder_path, train_data_path_phase_3, landmine_types, train_date_folders)\n",
    "dmf.create_landmine_folders_phase_3(test_data_path_phase_3, landmine_types)\n",
    "dmf.copy_images_to_landmine_folders_phase_3(folder_path, test_data_path_phase_3, landmine_types, test_date_folders)\n",
    "\n",
    "\n",
    "three_class_types = {\n",
    "    \"Surface\": [\"Mine 0cm depth\", \"Mine 1cm depth\"],\n",
    "    \"Deep\": [\"Mine 5cm depth\", \"Mine 10cm depth\"]\n",
    "}\n",
    "train_data_path_phase_2 = os.path.join(current_path, 'data', 'land_mine_phase_2', 'train')\n",
    "test_data_path_phase_2 = os.path.join(current_path, 'data', 'land_mine_phase_2', 'test')\n",
    "dmf.create_landmine_folders_phase_2(train_data_path_phase_2, three_class_types)\n",
    "dmf.copy_images_to_landmine_folders_phase_2(folder_path, train_data_path_phase_2, three_class_types, train_date_folders)\n",
    "dmf.create_landmine_folders_phase_2(test_data_path_phase_2, three_class_types)\n",
    "dmf.copy_images_to_landmine_folders_phase_2(folder_path, test_data_path_phase_2, three_class_types, test_date_folders)\n",
    "\n",
    "# 2-Class Landmine Types\n",
    "two_class_types = {\n",
    "    \"Free zone\": [\"Free zone\"],\n",
    "    \"Land_mine\": [\"Mine 0cm depth\", \"Mine 1cm depth\", \"Mine 5cm depth\", \"Mine 10cm depth\"]\n",
    "}\n",
    "train_data_path_phase_1 = os.path.join(current_path, 'data', 'land_mine_phase_1', 'train')\n",
    "test_data_path_phase_1 = os.path.join(current_path, 'data', 'land_mine_phase_1', 'test')\n",
    "dmf.create_landmine_folders_phase_1(train_data_path_phase_1, two_class_types)\n",
    "dmf.copy_images_to_landmine_folders_phase_1(folder_path, train_data_path_phase_1, two_class_types, train_date_folders)\n",
    "dmf.create_landmine_folders_phase_1(test_data_path_phase_1, two_class_types)\n",
    "dmf.copy_images_to_landmine_folders_phase_1(folder_path, test_data_path_phase_1, two_class_types, test_date_folders)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the data\n",
    "Show one random image from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(32)\n",
    "\n",
    "# Paths to train and test datasets\n",
    "train_data_path = Path(train_data_path_phase_3)\n",
    "test_data_path = Path(test_data_path_phase_3)\n",
    "\n",
    "# Get the list of image paths\n",
    "train_image_path_list = list(train_data_path.glob(\"*/*.jpg\"))\n",
    "test_image_path_list = list(test_data_path.glob(\"*/*.jpg\"))\n",
    "\n",
    "print(f\"Number of training images: {len(train_image_path_list)}\")\n",
    "print(f\"Number of testing images: {len(test_image_path_list)}\")\n",
    "\n",
    "# Select 8 random images\n",
    "random_image_paths = random.sample(train_image_path_list, 8)\n",
    "\n",
    "# Create a 4x4 grid (only using the first 8 slots for images)\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "\n",
    "# Flatten axes for easier iteration\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < len(random_image_paths):  # For the first 8 axes\n",
    "        image_path = random_image_paths[i]\n",
    "        img = Image.open(image_path)\n",
    "        image_class = image_path.parent.stem\n",
    "        \n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"Class: {image_class}\")\n",
    "        ax.axis('off')\n",
    "    else:  # Leave remaining slots blank\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification model\n",
    "ViT classification model\n",
    "Through transfer learning, we freeze the rest of the data and keep the head layer learnable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
    "pretrained_vit = torchvision.models.vit_b_16(weights=pretrained_vit_weights).to(device)\n",
    "\n",
    "# Transfer learning\n",
    "for parameter in pretrained_vit.parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "# # Modify the first convolution layer to accept 1-channel (grayscale) input\n",
    "# pretrained_vit.conv_proj = nn.Conv2d(\n",
    "#     in_channels=3,  # Grayscale image (1 channel)\n",
    "#     out_channels=768,  # Output channels\n",
    "#     kernel_size=16,  # Same kernel size\n",
    "#     stride=16  # Same stride\n",
    "# ).to(device)\n",
    "\n",
    "pretrained_vit.heads = nn.Sequential(\n",
    "    nn.Dropout(p = 0.2),\n",
    "    nn.Linear(in_features=768, out_features=2)\n",
    ").to(device)\n",
    "\n",
    "# Print a summary using torchinfo (uncomment for actual output)\n",
    "summary(model=pretrained_vit,\n",
    "        input_size=(16, 3, 224, 224), # (batch_size, color_channels, height, width)\n",
    "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "Prepare the data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main dataset\n",
    "batch_size = 16\n",
    "pretrained_vit_transforms = pretrained_vit_weights.transforms()\n",
    "print(pretrained_vit_transforms)\n",
    "\n",
    "# Augmentaed dataset to be added to the main dataset\n",
    "augmentation_transform = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust colors\n",
    "    transforms.RandomHorizontalFlip(p=1),  # Random horizontal flip\n",
    "    transforms.RandomVerticalFlip(p=0.3),  # Random vertical flip\n",
    "    transforms.RandomRotation(degrees=15, interpolation=InterpolationMode.BICUBIC),  # Random rotation\n",
    "    transforms.Resize(size=256, interpolation=InterpolationMode.BILINEAR),  # Resize to 256\n",
    "    transforms.CenterCrop(size=224),  # Center crop to 224x224\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(\n",
    "        mean=pretrained_vit_weights.transforms().mean,\n",
    "        std=pretrained_vit_weights.transforms().std  # Normalize with pretrained weights\n",
    "    )\n",
    "])\n",
    "\n",
    "# Change data here for 2 class, 3 class, and 5 class\n",
    "\n",
    "train_dataloader_pretrained, test_dataloader_pretrained, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_data_path_phase_1, \n",
    "    test_dir=test_data_path_phase_1,\n",
    "    transform=pretrained_vit_transforms,\n",
    "    batch_size=batch_size,\n",
    "    augmentation_transform=augmentation_transform\n",
    ")\n",
    "\n",
    "\n",
    "print(' ')\n",
    "print(f\"Class names: {class_names}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "\n",
    "print(' ')\n",
    "print(\"Number of training data: \", len(train_dataloader_pretrained) * batch_size)\n",
    "print(\"Number of testing data: \", len(test_dataloader_pretrained) * batch_size)\n",
    "\n",
    "# image_batch, label_batch = next(iter(train_dataloader_pretrained))\n",
    "# print(image_batch.shape, label_batch.shape)\n",
    "\n",
    "# image, label = image_batch[0], label_batch[0]\n",
    "# print(image.shape, label)\n",
    "\n",
    "# plt.imshow(image.permute(1, 2, 0))\n",
    "# plt.title(class_names[label])\n",
    "# plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the device\n",
    "print(f\"Working on device: {device}\")\n",
    "\n",
    "# Create optimizer and loss function\n",
    "optimizer = torch.optim.Adam(params=pretrained_vit.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Train the classifier head of the pretrained ViT feature extractor model\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "pretrained_vit_results = engine.train(\n",
    "    model=pretrained_vit,\n",
    "    train_dataloader=train_dataloader_pretrained,\n",
    "    test_dataloader=test_dataloader_pretrained,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=30,\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import plot_loss_curves\n",
    "\n",
    "plot_loss_curves(pretrained_vit_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from helper_functions import plot_roc_auc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "\n",
    "def plot_roc_auc(model: torch.nn.Module, \n",
    "                 dataloader: torch.utils.data.DataLoader, \n",
    "                 device: torch.device) -> None:\n",
    "    \"\"\"\n",
    "    Plots the ROC curve and calculates the AUC for a binary classification model.\n",
    "    \n",
    "    Parameters:\n",
    "        model (torch.nn.Module): Trained PyTorch model.\n",
    "        dataloader (torch.utils.data.DataLoader): DataLoader for the dataset.\n",
    "        device (torch.device): Device to perform computations on (e.g., \"cuda\" or \"cpu\").\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred_logits = model(X)\n",
    "            \n",
    "            # Convert logits to probabilities\n",
    "            y_pred_probs = torch.softmax(y_pred_logits, dim=1)[:, 1]  # Probability of class 1\n",
    "            \n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            all_probs.extend(y_pred_probs.cpu().numpy())\n",
    "    \n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='blue', label=f'AUC = {auc:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='red')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_roc_auc(model=pretrained_vit, \n",
    "             dataloader=test_dataloader_pretrained, \n",
    "             device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Som plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 16\n",
    "\n",
    "image_batch, label_batch = next(iter(train_dataloader_pretrained))\n",
    "print(image_batch.shape, label_batch.shape)\n",
    "\n",
    "image, label = image_batch[0], label_batch[0]\n",
    "print(image.shape, label)\n",
    "\n",
    "plt.imshow(image.permute(1, 2, 0))\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)\n",
    "\n",
    "conv2d = nn.Conv2d(in_channels=3, \n",
    "                   out_channels=768, # 3 x 16 x 16 = 768\n",
    "                   kernel_size=patch_size, \n",
    "                   stride=patch_size,\n",
    "                   padding=0)\n",
    "\n",
    "image_out_of_conv = conv2d(image.unsqueeze(0))\n",
    "print(image_out_of_conv.shape)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=10, figsize=(12, 12))\n",
    "\n",
    "for i, j in enumerate(range(10)):\n",
    "    axs[i].imshow(image_out_of_conv[0, j].detach().numpy())\n",
    "    axs[i].axis(False)\n",
    "\n",
    "\n",
    "# Create flatten layer\n",
    "#shape: (1, c, h, w)\n",
    "flatten = nn.Flatten(start_dim=2, # flatten feature_map_height (dimension 2)\n",
    "                     end_dim=3) # flatten feature_map_width (dimension 3)\n",
    "image_out_of_conv_flattened = flatten(image_out_of_conv)\n",
    "print(f\"Flattened image feature map shape: {image_out_of_conv_flattened.shape}\")\n",
    "#[1, 768, 196] = [batch_size, embedding_dimension, number_of_patches]\n",
    "#Should reshape to [batch_size, number_of_patches, embedding_dimension]\n",
    "image_out_of_conv_flattened_reshaped = image_out_of_conv_flattened.permute(0, 2, 1) # [batch_size, P^2•C, N] -> [batch_size, N, P^2•C]\n",
    "print(f\"Patch embedding sequence shape: {image_out_of_conv_flattened_reshaped.shape} -> [batch_size, num_patches, embedding_size]\")\n",
    "\n",
    "# Get a single flattened feature map\n",
    "single_flattened_feature_map = image_out_of_conv_flattened_reshaped[:, :, 0] # index: (batch_size, number_of_patches, embedding_dimension)\n",
    "\n",
    "plt.figure(figsize=(22, 22))\n",
    "plt.imshow(single_flattened_feature_map.detach().numpy())\n",
    "plt.title(f\"Flattened feature map shape: {single_flattened_feature_map.shape}\")\n",
    "plt.axis(False);\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
